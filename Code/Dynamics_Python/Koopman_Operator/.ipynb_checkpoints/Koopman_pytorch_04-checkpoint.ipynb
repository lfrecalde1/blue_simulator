{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74c7a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import casadi as ca\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from fancy_plots import fancy_plots_3\n",
    "from fancy_plots import plot_states_angles_estimation, plot_states_velocity_lineal_estimation, plot_states_velocity_angular_estimation, plot_control_states_estimation\n",
    "from fancy_plots import fancy_plots_2\n",
    "from fancy_plots import fancy_plots_1, plot_error_estimation, plot_states_position_estimation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch.nn.modules.container import T\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd8baa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3011a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_odometry(data, angle, vx, vy, vz, wx, wy, wz, vel_control, steer_control, samples_i, samples_f):\n",
    "    # Get size of the data\n",
    "    i, j = data.shape\n",
    "    # Init empty values\n",
    "    x = np.zeros((1, j), dtype = np.double)\n",
    "    y = np.zeros((1, j), dtype = np.double)\n",
    "    z = np.zeros((1, j), dtype = np.double)\n",
    "    quatenions = np.zeros((4, j), dtype = np.double)\n",
    "    orientation_aux = np.zeros((3, j), dtype = np.double)\n",
    "    \n",
    "    for k in range(0, j):\n",
    "        \n",
    "        # Get Position\n",
    "        x[:, k] = data[0, k]\n",
    "        y[:, k] = data[1, k]\n",
    "        z[:, k] = 0\n",
    "        \n",
    "        # Get quaternion\n",
    "        quatenions[:, k] = [data[2, k], data[3, k], data[4, k], data[5, k]]\n",
    "        \n",
    "        # Get Euler Angles\n",
    "        aux =  quatenions[:, k]\n",
    "        r = R.from_quat(aux)\n",
    "        orientation_aux[:, k] = r.as_euler('xyz', degrees = False)\n",
    "        \n",
    "    # get complete data of the system\n",
    "    h = np.array([x[0,:], y[0,:], z[0,:],\n",
    "                quatenions[0, :], quatenions[1, :], quatenions[2, :], quatenions[3, :],\n",
    "                orientation_aux[0, :], orientation_aux[1, :], orientation_aux[2, :],\n",
    "                angle[0, :]], dtype =np.double) \n",
    "    \n",
    "    # Get Velocities of the system\n",
    "    hp = np.array([vx[0, :], vy[0, :], vz[0, :], wx[0, :], wy[0, :], wz[0, :]], dtype = np.double)\n",
    "    T = np.array([vel_control[0,:], steer_control[0, :]], dtype = np.double)\n",
    "    return h[:, samples_i:samples_f+1], hp[:, samples_i:samples_f+1], T[:, samples_i:samples_f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6735c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_data(h, hp, T):\n",
    "    ## Position\n",
    "    x = h[0, :]\n",
    "    y = h[1, :]\n",
    "    ## Linear velocities\n",
    "    vx = hp[0, :]\n",
    "    vy = hp[1, :]\n",
    "    vz = hp[2, :]\n",
    "    \n",
    "    ## Get angular velocities\n",
    "    p = hp[3, :]\n",
    "    q = hp[4, :]\n",
    "    r = hp[5, :]\n",
    "    \n",
    "    ## Angular velocities vector\n",
    "    omega = hp[3:6, :]\n",
    "    \n",
    "    ## Orientacion\n",
    "    quaternion = h[3:7, :]\n",
    "    \n",
    "    ##euler\n",
    "    euler = h[7:10, :]\n",
    "    \n",
    "    ## Steer angle = \n",
    "    alpha = h[10, :]\n",
    "    \n",
    "    ## General states data\n",
    "    #X = np.array([euler[2,:], omega[2, :], alpha, vx, vy], dtype = np.double)\n",
    "    #X = np.array([euler[0, :], euler[1, :], euler[2, :], omega[0, :], omega[1, :], omega[2, :], alpha, vx, vy, x, y], dtype = np.double)\n",
    "    X = np.array([euler[2, :], omega[2, :], alpha, vx, x, y], dtype = np.double)\n",
    "    ## Control Action\n",
    "    U_ref = T[:, :]\n",
    "    \n",
    "    ## Get the dimension of the Data\n",
    "    i, j = X.shape\n",
    "    \n",
    "    X1 = X[:, 0:j-1]\n",
    "    X2 = X[:, 1:j]\n",
    "    return X1, X2, U_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1663ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def liftFun(x):\n",
    "    x_lift = []\n",
    "    for k in x: x_lift.append(k)\n",
    "    x_lift.append(np.tan(x[2, :]))\n",
    "\n",
    "    x_lift.append(np.tan(x[2, :])*x[3, :])\n",
    "\n",
    "    x_lift.append(np.cos(x[2, :])*x[3, :])\n",
    "    x_lift.append(np.sin(x[2, :])*x[3, :])\n",
    "    \n",
    "    x_lift.append(np.cos(x[0, :])*x[3, :])\n",
    "\n",
    "    x_lift.append(np.sin(x[0, :])*x[3, :])\n",
    "\n",
    "    x_lift = np.array(x_lift, dtype = np.double)\n",
    "    return x_lift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95b6bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def liftFun_vector(x):\n",
    "    x_lift = []\n",
    "    for k in x: x_lift.append(k)\n",
    "    x_lift.append(np.tan(x[2]))\n",
    "\n",
    "    x_lift.append(np.tan(x[2])*x[3])\n",
    "\n",
    "    x_lift.append(np.cos(x[2])*x[3])\n",
    "    x_lift.append(np.sin(x[2])*x[3])\n",
    "    \n",
    "    x_lift.append(np.cos(x[0])*x[3])\n",
    "\n",
    "    x_lift.append(np.sin(x[0])*x[3])\n",
    "\n",
    "    x_lift = np.array(x_lift, dtype = np.double)\n",
    "    return x_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baf573c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(A, data):\n",
    "    for i in range(0, data.shape[0]):\n",
    "        for j in range(0, data.shape[1]):\n",
    "            A[i, j] = data[i, j]\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77210744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_koopman(X_1, X_k, U, alpha, beta, n, m, n_normal):\n",
    "    # Create Matrices of the system\n",
    "    A = ca.MX.sym('A', n, n)\n",
    "    B = ca.MX.sym('B', n, m)\n",
    "    C_ones = ca.MX.eye(n_normal)\n",
    "    C_zeros = ca.MX.zeros(n_normal, n-n_normal)\n",
    "    C_a = ca.horzcat(C_ones, C_zeros)\n",
    "    \n",
    "    ## Create data in Casadi variables\n",
    "    i_states, j_states = X_1.shape\n",
    "    i_control, j_control = U.shape\n",
    "    \n",
    "    X_1_ca = ca.MX.zeros(i_states, j_states)\n",
    "    X_1_ca = create_matrix(X_1_ca, X_1)\n",
    "    \n",
    "    X_k_ca = ca.MX.zeros(i_states, j_states)\n",
    "    X_k_ca = create_matrix(X_k_ca, X_k)\n",
    "    \n",
    "    U_ca = ca.MX.zeros(i_control, j_control)\n",
    "    U_ca = create_matrix(U_ca, U)\n",
    "\n",
    "    ## Initial cost\n",
    "    obj = 0\n",
    "\n",
    "    args = {}\n",
    "    \n",
    "    for k in range(0, U_ca.shape[1]):\n",
    "        x_1 = C_a@X_1_ca[:, k]\n",
    "        x_k = C_a@X_k_ca[:, k]\n",
    "        \n",
    "        Gamma_k = X_k_ca[:, k]\n",
    "        Gamma_1 = X_1_ca[:, k]\n",
    "        \n",
    "        error_koop = Gamma_k - A@Gamma_1 - B@U_ca[:, k]\n",
    "        error_prediction = x_k - C_a@(A@Gamma_1 + B@U_ca[:, k])\n",
    "        obj = obj + beta*ca.norm_fro(error_koop) + ca.norm_fro(error_prediction) \n",
    "    \n",
    "    obj = obj + alpha*ca.norm_fro(A) + alpha*ca.norm_fro(B)\n",
    "\n",
    "    OPT_variables = ca.vertcat(A.reshape((-1, 1)), B.reshape((-1, 1)))\n",
    "    # Initial Values Problem \n",
    "    A_0 = ca.DM.eye(n)*0.1\n",
    "    B_0 = ca.DM.ones(n, m)*0.1\n",
    "\n",
    "    # Definition optimal control problem\n",
    "    nlp_prob = {'f': obj,'x': OPT_variables}\n",
    "    opts = {'ipopt': {'max_iter': 100, 'print_level': 1, 'acceptable_tol': 1e-8, 'acceptable_obj_change_tol': 1e-6},'print_time': 1}\n",
    "    \n",
    "    # Initial condition s definition\n",
    "    args['x0'] = ca.vertcat(A_0.reshape((-1, 1)), B_0.reshape((-1, 1)))\n",
    "    \n",
    "    # Defintion of the optimal control problem\n",
    "    solver = ca.nlpsol('solver', 'ipopt', nlp_prob, opts)\n",
    "    sol = solver(x0=args['x0'])\n",
    "\n",
    "    # Solution optimal control problem\n",
    "    Solution = sol['x']\n",
    "\n",
    "    Full_matrix = ca.reshape(Solution, n, n + m)\n",
    "    Full_matrix_np = Full_matrix.full()\n",
    "\n",
    "    # Get matrices\n",
    "    A_final = Full_matrix_np[0:n, 0:n]\n",
    "    B_final = Full_matrix_np[0:n, n:n+m]\n",
    "    return A_final, B_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bccec01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Matrices from mat file\n",
    "Data = scipy.io.loadmat('blue_data_02.mat')\n",
    "\n",
    "## Get odometry of the system\n",
    "data_odom_blue = Data['data_odom_blue']\n",
    "data_odom_blue = data_odom_blue.T\n",
    "\n",
    "## Get Control steer angle\n",
    "steering_control = Data['steering_control']\n",
    "steering_control = steering_control.T\n",
    "steering_control = steering_control*(np.pi/180)\n",
    "\n",
    "## Get Steer angle real\n",
    "steering_real = Data['steering_real']\n",
    "steering_real = steering_real.T\n",
    "steering_real = steering_real*(np.pi/180)\n",
    "\n",
    "## Get system velocities\n",
    "vx = Data['vel_real']\n",
    "vx = vx.T\n",
    "vy = Data['vy']\n",
    "vy = vy.T\n",
    "vz = Data['vz']\n",
    "vz = vz.T\n",
    "wx = Data['wx']\n",
    "wx = wx.T\n",
    "wy = Data['wy']\n",
    "wy = wy.T\n",
    "wz = Data['wz']\n",
    "wz = wz.T\n",
    "\n",
    "## Get desired frontal velocity\n",
    "\n",
    "vel_control = Data['vel_control']\n",
    "vel_control = vel_control.T\n",
    "\n",
    "h, hp, T = get_odometry(data_odom_blue, steering_real, vx, vy, vz, wx, wy, wz, vel_control, steering_control, 0, 3000)\n",
    "## Compute sample time of the system\n",
    "ts = 0.05\n",
    "t = np.zeros((T.shape[1]), dtype = np.double)\n",
    "for k in range(0, T.shape[1]-1):\n",
    "    t[k+1] = t[k] + ts\n",
    "\n",
    "\n",
    "## Get Data DMD\n",
    "X1_n, X2_n, U_n = get_simple_data(h, hp, T)\n",
    "n_normal = X1_n.shape[0]\n",
    "\n",
    "# Koopman Space\n",
    "X1 = liftFun(X1_n)\n",
    "X2 = liftFun(X2_n)\n",
    "U = U_n\n",
    "n = X1.shape[0]\n",
    "m = U.shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f06e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_init_(n_units, std=1):    \n",
    "    sampler = torch.distributions.Normal(torch.Tensor([0]), torch.Tensor([std/n_units]))\n",
    "    Omega = sampler.sample((n_units, n_units))[..., 0]  \n",
    "    return Omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a060ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class koop_model(torch.nn.Module):\n",
    "    def __init__(self, encode_layers, n, m, n_normal, n_network):\n",
    "        super(koop_model,self).__init__()\n",
    "        Layers = OrderedDict()\n",
    "        aux = 0\n",
    "        for layer_i in range(len(encode_layers)-1):\n",
    "            if layer_i ==0:\n",
    "                Layers[\"dropout_{}\".format(layer_i)] = nn.Dropout(0.2)\n",
    "            Layers[\"linear_{}\".format(layer_i)] = nn.Linear(encode_layers[layer_i],encode_layers[layer_i+1])\n",
    "            if layer_i != len(encode_layers)-2:\n",
    "                aux = aux + 1\n",
    "                if aux == 1:\n",
    "                    Layers[\"tanh_{}\".format(layer_i)] = nn.Tanh()\n",
    "                elif aux == 2:\n",
    "                    Layers[\"cos_{}\".format(layer_i)] = nn.ReLU()\n",
    "                elif aux == 3:\n",
    "                    Layers[\"sin_{}\".format(layer_i)] = nn.Sigmoid()\n",
    "                    aux = 0\n",
    "        self.dropout = nn.Dropout(0.2)     \n",
    "        self.encode_net = nn.Sequential(Layers)\n",
    "        self.Nkoopman = n\n",
    "        self.u_dim = m\n",
    "        self.A = nn.Linear(n, n,bias=False)\n",
    "        self.A.weight.data = gaussian_init_(n, std=1)\n",
    "        U, _, V = torch.svd(self.A.weight.data)\n",
    "        self.A.weight.data = torch.mm(U, V.t()) * 0.9\n",
    "        self.B = nn.Linear(m, n,bias=False)\n",
    "       \n",
    "        # C complete\n",
    "        self.C_eye = torch.eye(n_normal, device=device)\n",
    "        self.C_zeros = torch.zeros((n_normal, n - n_normal), device=device)\n",
    "        self.C= torch.cat((self.C_eye, self.C_zeros), dim=1)\n",
    "        self.C = self.C.double()\n",
    "        print(self.C.shape)\n",
    "        \n",
    "        self.C_eye_1 = torch.eye(n_normal, device=device)\n",
    "        self.C_zeros_1 = torch.zeros((n_normal, n - n_normal - n_network), device=device)\n",
    "        self.C_1= torch.cat((self.C_eye_1, self.C_zeros_1), dim=1)\n",
    "        self.C_1 = self.C_1.double()\n",
    "        \n",
    "\n",
    "    def encode(self,x):\n",
    "        return torch.cat([x,self.encode_net(x)],axis=-1)\n",
    "    \n",
    "    #def forward(self,x,u):\n",
    "        #return self.lA(x)+self.lB(u)\n",
    "    def forward(self, X1, U):\n",
    "        Gamma_1 = X1\n",
    "        \n",
    "        output_1 = self.A(Gamma_1) + self.B(U)\n",
    "        output_2 = (self.A(Gamma_1) + self.B(U))@self.C.T\n",
    "        \n",
    "        return output_1, output_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8723630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_koopman(X1, X2, U, net):\n",
    "    \n",
    "    x_k = net.encode(X2.T)@net.C.T\n",
    "    Gamma_k = net.encode(X2.T)\n",
    "    \n",
    "    X1 = net.encode(X1.T)\n",
    "    U = U.T\n",
    "    \n",
    "    # output Neural Network\n",
    "    output_koopman, output_prediction = net.forward(X1, U)\n",
    "    \n",
    "    # Get Error\n",
    "    error_koop = Gamma_k - output_koopman\n",
    "    error_prediction = x_k - output_prediction\n",
    "    \n",
    "    error_prediction[:, 0] = 2*error_prediction[:, 0]\n",
    "    error_prediction[:, 1] = 2*error_prediction[:, 1]\n",
    "    \n",
    "    error_koop_new = error_koop.reshape((error_koop.shape[0]*error_koop.shape[1], 1))\n",
    "    error_prediction_new = error_prediction.reshape((error_prediction.shape[0]*error_prediction.shape[1], 1))\n",
    "    \n",
    "    loss =  0.5*torch.norm(error_koop_new, p=2) + 1*torch.norm(error_prediction_new, p=2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a22c4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eig_loss(net):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    A = net.A.weight\n",
    "    c = torch.linalg.eigvals(A).abs()-torch.ones(1,dtype=torch.float64).to(device)\n",
    "    mask = c>0\n",
    "    loss = c[mask].sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49bb70bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## New Data in Pytorch\n",
    "X1_tensor =  torch.tensor(X1,  requires_grad = True).to(device)\n",
    "X1_tensor = X1_tensor.double()\n",
    "\n",
    "X2_tensor =  torch.tensor(X2).to(device)\n",
    "X2_tensor = X2_tensor.double()\n",
    "\n",
    "U_tensor =  torch.tensor(U, requires_grad = True).to(device)\n",
    "U_tensor =  U_tensor.double()\n",
    "\n",
    "U_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9144787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "12\n",
      "torch.Size([6, 42])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 6 and 12 (The offending index is 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(n)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(X1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m neural_network \u001b[38;5;241m=\u001b[39m \u001b[43mkoop_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_normal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 38\u001b[0m, in \u001b[0;36mkoop_model.__init__\u001b[0;34m(self, encode_layers, n, m, n_normal, n_network)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_eye_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(n \u001b[38;5;241m-\u001b[39m n_network, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_zeros_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((n_normal, n \u001b[38;5;241m-\u001b[39m n_normal), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_1\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC_eye_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC_zeros_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_1\u001b[38;5;241m.\u001b[39mdouble()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 6 and 12 (The offending index is 0)"
     ]
    }
   ],
   "source": [
    "encode_dim = 30\n",
    "layer_depth = 6\n",
    "layer_width = 18\n",
    "layers = [n_normal] + [layer_width]*layer_depth+[encode_dim]\n",
    "n = X1.shape[0] + encode_dim\n",
    "print(n)\n",
    "print(X1.shape[0])\n",
    "neural_network = koop_model(layers, n, m, n_normal, encode_dim)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Yes\")\n",
    "    neural_network.cuda() \n",
    "neural_network.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de3b641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(neural_network.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35a713bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 42])\n",
      "torch.Size([3000, 6])\n"
     ]
    }
   ],
   "source": [
    "losses = defaultdict(lambda: defaultdict(list))\n",
    "num_epochs = 3000\n",
    "Kbatch_size = 100\n",
    "aux = neural_network.encode(X1_tensor[0, :].T)\n",
    "Kindex = list(range(X1_tensor.shape[1]))\n",
    "random.shuffle(Kindex)\n",
    "X1_tensor[:, Kindex[:Kbatch_size]].shape\n",
    "a, b = neural_network.forward(X1_tensor[:, :].T, U_tensor[:, :].T)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dbdd8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Koopman Neural Network: training epoch:   0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 42])\n",
      "torch.Size([100, 6])\n",
      "torch.Size([100, 42])\n",
      "torch.Size([100, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function AddmmBackward returned an invalid gradient at index 1 - got [100, 6] but expected shape compatible with [100, 12]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Backward pass: compute gradient of the loss with respect to model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# parameters\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calling the step function on an Optimizer makes an update to its\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# parameters\u001b[39;00m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/py3-learning/lib/python3.8/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3-learning/lib/python3.8/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function AddmmBackward returned an invalid gradient at index 1 - got [100, 6] but expected shape compatible with [100, 12]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs), desc=\"Koopman Neural Network: training epoch\"):\n",
    "        #loss.backward(retain_graph = True)\n",
    "        Kindex = list(range(X1_tensor.shape[1]))\n",
    "        random.shuffle(Kindex)\n",
    "        \n",
    "        \n",
    "        Kloss = cost_koopman(X1_tensor[:, Kindex[:Kbatch_size]], X2_tensor[:, Kindex[:Kbatch_size]], U_tensor[:, Kindex[:Kbatch_size]], neural_network)\n",
    "        Eloss =  Eig_loss(neural_network)\n",
    "        loss = Kloss + 0.01*Eloss\n",
    "\n",
    "        # Optimize Network\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        losses[\"Koopman\"][\"collocation\"].append(loss.item())\n",
    "        losses[\"Koopman\"][\"num_epochs\"].append(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791a266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape Data\n",
    "## Load Matrices from mat file\n",
    "Data = scipy.io.loadmat('blue_data_02.mat')\n",
    "\n",
    "## Get odometry of the system\n",
    "data_odom_blue = Data['data_odom_blue']\n",
    "data_odom_blue = data_odom_blue.T\n",
    "\n",
    "## Get Control steer angle\n",
    "steering_control = Data['steering_control']\n",
    "steering_control = steering_control.T\n",
    "steering_control = steering_control*(np.pi/180)\n",
    "\n",
    "## Get Steer angle real\n",
    "steering_real = Data['steering_real']\n",
    "steering_real = steering_real.T\n",
    "steering_real = steering_real*(np.pi/180)\n",
    "\n",
    "## Get system velocities\n",
    "vx = Data['vel_real']\n",
    "vx = vx.T\n",
    "vy = Data['vy']\n",
    "vy = vy.T\n",
    "vz = Data['vz']\n",
    "vz = vz.T\n",
    "wx = Data['wx']\n",
    "wx = wx.T\n",
    "wy = Data['wy']\n",
    "wy = wy.T\n",
    "wz = Data['wz']\n",
    "wz = wz.T\n",
    "\n",
    "## Get desired frontal velocity\n",
    "\n",
    "vel_control = Data['vel_control']\n",
    "vel_control = vel_control.T\n",
    "\n",
    "h, hp, T = get_odometry(data_odom_blue, steering_real, vx, vy, vz, wx, wy, wz, vel_control, steering_control, 0, 500)\n",
    "## Compute sample time of the system\n",
    "ts = 0.05\n",
    "t = np.zeros((T.shape[1]), dtype = np.double)\n",
    "for k in range(0, T.shape[1]-1):\n",
    "    t[k+1] = t[k] + ts\n",
    "\n",
    "\n",
    "## Get Data DMD\n",
    "X1_n, X2_n, U_n = get_simple_data(h, hp, T)\n",
    "n_normal = X1_n.shape[0]\n",
    "\n",
    "# Koopman Space\n",
    "X1 = (X1_n)\n",
    "X2 = (X2_n)\n",
    "U = U_n\n",
    "\n",
    "A_a = neural_network.A.weight.cpu()\n",
    "A_a = A_a.double()\n",
    "A_a = A_a.detach().numpy()\n",
    "\n",
    "B_a = neural_network.B.weight.cpu()\n",
    "B_a = B_a.double()\n",
    "B_a = B_a.detach().numpy()\n",
    "\n",
    "C_ones = np.eye(n_normal, dtype = np.double)\n",
    "C_zeros = np.zeros((n_normal, n - n_normal), dtype=np.double)\n",
    "C_a = np.hstack((C_ones, C_zeros))\n",
    "\n",
    "## Plot matrix A\n",
    "plt.imshow(A_a)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "#\n",
    "# Plot matrix B\n",
    "plt.imshow(B_a)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "#\n",
    "# New variables in order to verify the identification\n",
    "x_estimate = np.zeros((n_normal, X1.shape[1]+1), dtype=np.double)\n",
    "output_estimate = np.zeros((n_normal, U.shape[1]), dtype=np.double)\n",
    "output_real = np.zeros((n_normal, U.shape[1]), dtype=np.double)\n",
    "error_vector = np.zeros((n_normal, U.shape[1]), dtype=np.double)\n",
    "norm_error = np.zeros((1, U.shape[1]), dtype = np.double)\n",
    "\n",
    "\n",
    "# Tensors of the system\n",
    "X1_tensor =  torch.tensor(X1).to(device)\n",
    "X1_tensor = X1_tensor.double()\n",
    "\n",
    "X2_tensor =  torch.tensor(X2).to(device)\n",
    "X2_tensor = X2_tensor.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_aux_estimate = neural_network.encode(X1_tensor[:, 0])\n",
    "x_aux_estimate = x_aux_estimate.cpu().double().detach().numpy()\n",
    "# Initial value\n",
    "x_estimate[:, 0] = C_a@x_aux_estimate\n",
    "\n",
    "for k in range(0, U.shape[1]):\n",
    "    output_estimate[:, k] = x_estimate[:, k]\n",
    "    \n",
    "    output_numpy_pytorch = torch.from_numpy(X1[:, k]).to(device).double()\n",
    "    output_aux = neural_network.encode(output_numpy_pytorch)\n",
    "    \n",
    "    output_aux = output_aux.cpu().double().detach().numpy()\n",
    "    output_real[:, k] = C_a@output_aux\n",
    "\n",
    "    error_vector[:, k] = output_real[:, k] - output_estimate[:, k]\n",
    "    norm_error[:, k] = np.linalg.norm(error_vector[:, k])\n",
    "    \n",
    "    # transformation between pytorch an numpy\n",
    "    aux_numpy_pytorch = torch.from_numpy(x_estimate[:, k]).to(device).double()\n",
    "\n",
    "    x_aux_estimate = neural_network.encode(aux_numpy_pytorch)\n",
    "    x_aux_estimate = x_aux_estimate.cpu().double().detach().numpy()\n",
    "    \n",
    "    aux_states = x_aux_estimate\n",
    "    x_estimate[:, k+1] = C_a@(A_a@aux_states + B_a@U[:, k])\n",
    "\n",
    "print(\"Error estimation norm\")\n",
    "print(np.linalg.norm(norm_error))\n",
    "eig_A, eigv_A = np.linalg.eig(A_a)\n",
    "print(\"Print Eigvalues A\")\n",
    "print(eig_A)\n",
    "\n",
    "fig13, ax13, ax23, ax33 = fancy_plots_3()\n",
    "plot_states_angles_estimation(fig13, ax13, ax23, ax33, h[7:10, :], output_estimate[:, :], t, \"Euler Angles Of the system\")\n",
    "plt.show()\n",
    "\n",
    "fig15, ax15, ax25, ax35 = fancy_plots_3()\n",
    "plot_states_velocity_lineal_estimation(fig15, ax15, ax25, ax35, hp[0:3, :], output_estimate[:, :], t, \"Lineal Velocity of the system\")\n",
    "plt.show()\n",
    "\n",
    "fig16, ax16, ax26, ax36 = fancy_plots_3()\n",
    "plot_states_velocity_angular_estimation(fig16, ax16, ax26, ax36, hp[3:6, :], output_estimate[:, :], t, \"Angular Velocity of the system\")\n",
    "plt.show()\n",
    "\n",
    "fig17, ax17, ax27 = fancy_plots_2()\n",
    "plot_control_states_estimation(fig17, ax17, ax27, h[:, :], hp[:, :], output_estimate[:, :], t, \"Control and Real Values of the system\")\n",
    "plt.show()\n",
    "\n",
    "fig14, ax14, ax24, ax34 = fancy_plots_3()\n",
    "plot_states_position_estimation(fig14, ax14, ax24, ax34, h[0:3, :], output_estimate[:, :], t, \"Position of the system\")\n",
    "plt.show()\n",
    "\n",
    "fig18, ax18 = fancy_plots_1()\n",
    "plot_error_estimation(fig18, ax18, norm_error, t, 'Error Norm of the Estimation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde259e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[\"Koopman\"][\"collocation\"]\n",
    "costo = np.array(losses[\"Koopman\"][\"collocation\"])\n",
    "epochs = np.array(losses[\"Koopman\"][\"num_epochs\"])\n",
    "costo = costo.reshape(1, costo.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a56627",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig19, ax19 = fancy_plots_1()\n",
    "plot_error_estimation(fig19, ax19, costo, epochs, 'Training Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2075ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396cf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fa8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ff8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda7dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae632075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7324ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0215e383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092011b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3e869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6aedbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297cc8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
